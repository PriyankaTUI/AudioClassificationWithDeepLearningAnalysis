{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningWithoutForgetting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+c9nIppxwtXswgDsq6MON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc0a96f88726486d8921413609c24833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9c095fcab8d430a8e30d31eb0123cec",
              "IPY_MODEL_07a3386421fb49b68ef2dac6bbc66754",
              "IPY_MODEL_008c6bf365c244188f02fd81a2b793ce"
            ],
            "layout": "IPY_MODEL_98d57445399b4c69a7636a21ec95e3dd"
          }
        },
        "d9c095fcab8d430a8e30d31eb0123cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b5b1ac206e4eb5b4f304f18d27a652",
            "placeholder": "​",
            "style": "IPY_MODEL_66a5b1c01c424ce682dff4addd2fa662",
            "value": "100%"
          }
        },
        "07a3386421fb49b68ef2dac6bbc66754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_969a11881ab84ae4adfc042a27f8fd9d",
            "max": 2428923189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e4fe39135634337a6689a806ab536d9",
            "value": 2428923189
          }
        },
        "008c6bf365c244188f02fd81a2b793ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90160ff0b4c4a8684e6c5ef2c548366",
            "placeholder": "​",
            "style": "IPY_MODEL_0d739e9ebdee436ab3f120b97767c5fb",
            "value": " 2.26G/2.26G [00:11&lt;00:00, 219MB/s]"
          }
        },
        "98d57445399b4c69a7636a21ec95e3dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b5b1ac206e4eb5b4f304f18d27a652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a5b1c01c424ce682dff4addd2fa662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "969a11881ab84ae4adfc042a27f8fd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4fe39135634337a6689a806ab536d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e90160ff0b4c4a8684e6c5ef2c548366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d739e9ebdee436ab3f120b97767c5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaTUI/AudioClassificationWithDeepLearningAnalysis/blob/master/LearningWithoutForgetting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxt-h3EMUu3",
        "outputId": "10672101-ce09-4827-9c5d-364bfca1b33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AudioClassificationWithDeepLearningAnalysis'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 44 (delta 13), reused 28 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n",
            "/content/AudioClassificationWithDeepLearningAnalysis\n",
            "/content/AudioClassificationWithDeepLearningAnalysis\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PriyankaTUI/AudioClassificationWithDeepLearningAnalysis.git\n",
        "%cd AudioClassificationWithDeepLearningAnalysis\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import models\n",
        "import copy\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "uCT7DXOENMac"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding google speech command dataset"
      ],
      "metadata": {
        "id": "1TMCicA5CEc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "\n",
        "dataset = torchaudio.datasets.SPEECHCOMMANDS('./dataset/data/' , url = 'speech_commands_v0.02', folder_in_archive= 'SpeechCommands',  download = True)"
      ],
      "metadata": {
        "id": "BivZSZrnCDYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "bc0a96f88726486d8921413609c24833",
            "d9c095fcab8d430a8e30d31eb0123cec",
            "07a3386421fb49b68ef2dac6bbc66754",
            "008c6bf365c244188f02fd81a2b793ce",
            "98d57445399b4c69a7636a21ec95e3dd",
            "63b5b1ac206e4eb5b4f304f18d27a652",
            "66a5b1c01c424ce682dff4addd2fa662",
            "969a11881ab84ae4adfc042a27f8fd9d",
            "9e4fe39135634337a6689a806ab536d9",
            "e90160ff0b4c4a8684e6c5ef2c548366",
            "0d739e9ebdee436ab3f120b97767c5fb"
          ]
        },
        "outputId": "34344736-2b54-4f46-997d-fa587a194537"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc0a96f88726486d8921413609c24833"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split dataset and add to dataloder.\n",
        "\n",
        "Use different transformation for it"
      ],
      "metadata": {
        "id": "MXB7gRDeIMU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = sorted(list(set(datapoint[2] for datapoint in dataset)))\n",
        "labels"
      ],
      "metadata": {
        "id": "XxovDvPIaw9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd4546c-9b43-4ba6-9262-ddaf18da03f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['backward',\n",
              " 'bed',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'dog',\n",
              " 'down',\n",
              " 'eight',\n",
              " 'five',\n",
              " 'follow',\n",
              " 'forward',\n",
              " 'four',\n",
              " 'go',\n",
              " 'happy',\n",
              " 'house',\n",
              " 'learn',\n",
              " 'left',\n",
              " 'marvin',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'off',\n",
              " 'on',\n",
              " 'one',\n",
              " 'right',\n",
              " 'seven',\n",
              " 'sheila',\n",
              " 'six',\n",
              " 'stop',\n",
              " 'three',\n",
              " 'tree',\n",
              " 'two',\n",
              " 'up',\n",
              " 'visual',\n",
              " 'wow',\n",
              " 'yes',\n",
              " 'zero']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# random_targets = random.sample(labels, 3)\n",
        "# print(f\"Randomly selected tagets: {random_targets}\")\n",
        "\n",
        "random_targets = ['right', 'down', 'yes']\n",
        "print(f\"Randomly selected tagets: {random_targets}\")\n",
        "\n",
        "digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "labels = digits + random_targets\n",
        "print(f\"List of all target classes: {labels}\"\n",
        ")\n",
        "def label_to_index(label):\n",
        "    # Return the position of the word in labels\n",
        "    return torch.tensor(labels.index(label))\n",
        "\n",
        "\n",
        "def index_to_label(index):\n",
        "    # Return the word corresponding to the index in labels\n",
        "    # This is the inverse of label_to_index\n",
        "    return labels[index]\n",
        "\n",
        "tensors = []\n",
        "targets = []\n",
        "\n",
        "#parameters for MFCC transformation\n",
        "n_fft = 2048\n",
        "win_length = None\n",
        "hop_length = 512\n",
        "n_mels = 256\n",
        "n_mfcc = 256\n",
        "\n",
        "for waveform, sample_rate, label, *_ in dataset:\n",
        "  if label in random_targets:\n",
        "    if sample_rate == 16000:\n",
        "      if waveform.shape == (1, 16000):\n",
        "        tensors += [torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=32, \n",
        "                                               melkwargs={\n",
        "                                                            'n_fft': n_fft,\n",
        "                                                            'n_mels': n_mels,\n",
        "                                                            'hop_length': hop_length,\n",
        "                                                            'mel_scale': 'htk',\n",
        "                                                          }\n",
        "                                                          )(waveform)]\n",
        "        targets += [label_to_index(label)]\n",
        "\n",
        "print(f\"indext for selected targets: {label_to_index(random_targets[0])} , {label_to_index(random_targets[1])}, {label_to_index(random_targets[2])}\")\n",
        "print(len(tensors))\n",
        "print(len(targets))\n",
        "print(f\"Shape of waveform after MFCC wit n_mfcc=32: {tensors[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi4YQHdrcoIz",
        "outputId": "9c2a9c26-42e4-4605-8b9c-c2bb6e0ebaca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected tagets: ['right', 'down', 'yes']\n",
            "List of all target classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'right', 'down', 'yes']\n",
            "indext for selected targets: 10 , 11, 12\n",
            "10720\n",
            "10720\n",
            "Shape of waveform after MFCC wit n_mfcc=32: torch.Size([1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "waveform, sample_rate, label, *_ =  dataset[0]\n",
        "n_fft = 2048\n",
        "win_length = None\n",
        "hop_length = 512\n",
        "n_mels = 256\n",
        "n_mfcc = 256\n",
        "sample = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=32,\n",
        "                                    melkwargs={\n",
        "      'n_fft': n_fft,\n",
        "      'n_mels': n_mels,\n",
        "      'hop_length': hop_length,\n",
        "      'mel_scale': 'htk',\n",
        "    }\n",
        "    )(waveform)\n",
        "\n",
        "print(sample.shape)"
      ],
      "metadata": {
        "id": "VEYClyI3FD8D",
        "outputId": "6f2979f4-2d8b-4743-9c2e-52322a7f8a07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.Resample(16000, 16000),\n",
        "    torchaudio.transforms.MFCC(sample_rate=8000)\n",
        ")\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "  mfcc = []\n",
        "  for tensor, target in data:\n",
        "    mfcc += train_audio_transforms(tensor)\n",
        "  return mfcc, targets\n"
      ],
      "metadata": {
        "id": "3q0Wpk21iJ0m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpeechCommandSubDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,data,labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        # self.label_dict = list_dir\n",
        "        # self.transform = transform\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)    \n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "tY4N1iJGnFaL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,random_split,Dataset\n",
        "\n",
        "valid_dataset = SpeechCommandSubDataset(tensors, targets)\n",
        "traindata, testdata = random_split(valid_dataset, [round(len(valid_dataset)*.8), round(len(valid_dataset)*.2)])\n",
        "\n",
        "\n",
        "trainloader = DataLoader(traindata, batch_size=5, shuffle=True)\n",
        "testloader = DataLoader(testdata, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "Mx10H_kmH0xv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "train_features, train_labels = next(iter(trainloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "img = train_features[1].squeeze()\n",
        "label = train_labels[1]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "img = train_features[2].squeeze()\n",
        "label = train_labels[3]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "img = train_features[3].squeeze()\n",
        "label = train_labels[3]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "print(f\"Label: {label}\")\n",
        "# grid = make_grid(train_features)\n",
        "# show(grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PWS0P5FIKNKv",
        "outputId": "dcbe34b6-3eb6-4b3c-efc6-ce4bb2fb423d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([5, 1, 32, 32])\n",
            "Labels batch shape: torch.Size([5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32])\n",
            "Label: 11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32])\n",
            "Label: 11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32])\n",
            "Label: 11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 32])\n",
            "Label: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying to add new class parameters to the model: need tocheck how many nodes get added to analyse how much comutation would incease**"
      ],
      "metadata": {
        "id": "VYNTNI0uzy6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Selected device is: {device}\")\n",
        "model = models.cnnModel()\n",
        "pretrained_model_path = \"./savedmodels/best_model_state.pt\"\n",
        "model.load_state_dict(copy.deepcopy(torch.load(pretrained_model_path, map_location='cpu')), strict=False)\n",
        "\n",
        "#add new class parameters , here we have added 3 new classes\n",
        "input_features = model.fc3.in_features\n",
        "output_features = model.fc3.out_features\n",
        "print(f\"Pre-trained model input features: {input_features}\")\n",
        "print(f\"Pre-trained model output features: {output_features}\")\n",
        "\n",
        "params = list(model.parameters())\n",
        "print(f\"Number of total parameters used in a network: {len(params)}\")\n",
        "print(f\"Old model: {model}\")\n",
        "\n",
        "new_output_features = output_features + len(random_targets)\n",
        "print(f\"new output features: {new_output_features}\")\n",
        "\n",
        "model.fc3 = nn.Linear(in_features=input_features, out_features= new_output_features)\n",
        "input_features = model.fc3.in_features\n",
        "output_features = model.fc3.out_features\n",
        "print(f\"New model input features: {input_features}\")\n",
        "print(f\"New model output features: {output_features}\")\n",
        "\n",
        "params = list(model.parameters())\n",
        "print(f\"Number of total parameters used in a network: {len(params)}\")\n",
        "print(f\"New model; {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE6meEWizyex",
        "outputId": "4a666a86-5071-4e16-bb73-c437aa46b16d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device is: cpu\n",
            "Pre-trained model input features: 256\n",
            "Pre-trained model output features: 11\n",
            "Number of total parameters used in a network: 8\n",
            "Old model: Net(\n",
            "  (conv): Conv2d(1, 512, kernel_size=(16, 16), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=11, bias=True)\n",
            ")\n",
            "new output features: 14\n",
            "New model input features: 256\n",
            "New model output features: 14\n",
            "Number of total parameters used in a network: 8\n",
            "New model; Net(\n",
            "  (conv): Conv2d(1, 512, kernel_size=(16, 16), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=14, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv2d(1, 512, kernel_size=(16, 16), stride=(1, 1))\n",
        "logits = F.leaky_relu(conv1(train_features))\n",
        "print(f\"Shape after conv layer 1: {logits.shape}\")\n",
        "pool = nn.MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
        "logits = pool(logits)\n",
        "print(f\"Shape after max_pool conv layer 1: {logits.shape}\")\n",
        "drop = nn.Dropout(p=0.25)\n",
        "logits = drop(logits)\n",
        "print(f\"Shape after drop: {logits.shape}\")\n",
        "# print(f\"shape of 1D converted logits to pass to Linear layer further: {torch.flatten(logits).shape}\")\n",
        "#\n",
        "logits = logits.view(logits.size(0),-1)\n",
        "# fc1 = nn.Linear(in_features=512*2*8, out_features=1024, bias=True). # in case of input([1, 32, 81])\n",
        "fc1 = nn.Linear(in_features=2048, out_features=1024, bias=True)\n",
        "logits  = F.leaky_relu(fc1(logits))\n",
        "print(f\"Shape after fc1: {logits.shape}\")\n",
        "\n",
        "fc2 = nn.Linear(in_features=1024, out_features=256, bias=True)\n",
        "logits = drop(logits)\n",
        "logits = F.leaky_relu(fc2(logits))\n",
        "print(f\"Shape after fc2: {logits.shape}\")\n",
        "\n",
        "fc3 = nn.Linear(in_features=256, out_features=14, bias=True)\n",
        "logits = fc3(logits)\n",
        "print(f\"Shape after fc3: {logits.shape}\")\n",
        "\n",
        "#todo: change 11 to 10 classes for pre-trained model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs5_scNgOYK-",
        "outputId": "b29a1c0e-07db-4e46-e174-018141111fbe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after conv layer 1: torch.Size([5, 512, 17, 17])\n",
            "Shape after max_pool conv layer 1: torch.Size([5, 512, 2, 2])\n",
            "Shape after drop: torch.Size([5, 512, 2, 2])\n",
            "Shape after fc1: torch.Size([5, 1024])\n",
            "Shape after fc2: torch.Size([5, 256])\n",
            "Shape after fc3: torch.Size([5, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Entropy loss and Distillation loss**:\n",
        "\n",
        "\n",
        "\n",
        "In pytorch nn.crossEntropyLoss already applied softmax function:\n",
        "\n",
        "nn.crossEntropyLoss = nn.LogSoftmax + nn.NLLLoss\n",
        "\n",
        "therefore, no sofmax in last layer and y_actual should be one hot encoded and logits should be raw from linera layer"
      ],
      "metadata": {
        "id": "IuU1SWHM5Euu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "#lets try with creating functions from scratch\n",
        "T = 1\n",
        "def softmax(logits):\n",
        "  return np.exp(logits/T)/np.sum(np.exp(logits/T), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "y_pred = softmax(x)\n",
        "print(f\"softmax output with numpy: {y_pred}\")\n",
        "\n",
        "#in pytorch\n",
        "x = torch.tensor([[2.0, 1.0, 0.1], [3.0, 1.0, 0.1]])\n",
        "y_pred = torch.softmax(x/T, dim=0)\n",
        "print(f\"softmax output with pytorch: {y_pred}\")\n",
        "\n",
        "#3d tensor softmax\n",
        "x = torch.tensor([[[2.0, 1.0, 0.1], [1.0, 1.0, 0.1]], [[2.0, 1.0, 0.1], [2.0, 1.0, 0.1]]])\n",
        "print(f\"shape of tensor {x.shape}\")\n",
        "y_pred = torch.softmax(x/T, dim=0)\n",
        "print(f\"softmax output with pytorch for 3D tensor in dim 0: {y_pred}\")\n",
        "y_pred = torch.softmax(x/T, dim=1)\n",
        "print(f\"softmax output with pytorch for 3D tensor in dim 1: {y_pred}\")\n",
        "y_pred = torch.softmax(x/T, dim=2)\n",
        "print(f\"softmax output with pytorch for 3D tensor in dim 2: {y_pred}\")\n",
        "#Cross entropy\n",
        "def cross_entropy(actual, predicted):\n",
        "  #predicted should be softmax of logits\n",
        "  #actual should be one hot encoded\n",
        "  loss = -np.sum(actual * np.log(predicted))\n",
        "  return loss #not normalized\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "y_actual = np.array([0, 1, 0])\n",
        "loss = cross_entropy(y_actual, softmax(x))\n",
        "print(f\"cross entropy loss with numpy: {loss}\")\n",
        "\n",
        "#in pytorch\n",
        "#x should be of size nsamples x nclasses (1x3)\n",
        "x = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "y_actual = torch.tensor([1]) #no hot encoded , only pass index of the class\n",
        "loss = nn.CrossEntropyLoss()\n",
        "l = loss(x, y_actual)\n",
        "print(f\"cross entropy loss with pytorch: {l.item()}\")\n",
        "\n",
        "\n",
        "#Distillation loss\n",
        "##temerature value decide how much weight should give to smaller propabilities\n",
        "##hight T value higher weightage to smaller probabilities \n",
        "T = 2\n",
        "y_pred = F.softmax(x/T, dim=1)\n",
        "print(f\"softmax output with pytorch functional: {y_pred}\")\n",
        "\n",
        "\n",
        "def knowledge_distillation_loss(old_logits, updated_logits, T):\n",
        "  prob_old_logits = F.softmax(old_logits/T, dim=1)\n",
        "  # print(prob_old_logits.shape)\n",
        "  log_prob_updated_logits = F.softmax(updated_logits/T, dim=1)\n",
        "  # print(log_prob_updated_logits.shape)\n",
        "  dist_loss = - (prob_old_logits * log_prob_updated_logits).sum(dim=1)\n",
        "  # print(dist_loss.shape)\n",
        "  dist_loss = dist_loss.mean()\n",
        "  return dist_loss\n",
        "\n",
        "#e.g 3 classes --> 3 labels of tensor size([3])\n",
        "old_logits = torch.rand(5,11)\n",
        "updated_logits = torch.rand(5,11)\n",
        "T = 1\n",
        "kd_loss = knowledge_distillation_loss(old_logits, updated_logits, T)\n",
        "print(f\"Knowledge distillation: {kd_loss} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKPVVawV5EQC",
        "outputId": "94374fe6-e9f7-410d-c62c-5ede7c1c0b9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax output with numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax output with pytorch: tensor([[0.2689, 0.5000, 0.5000],\n",
            "        [0.7311, 0.5000, 0.5000]])\n",
            "shape of tensor torch.Size([2, 2, 3])\n",
            "softmax output with pytorch for 3D tensor in dim 0: tensor([[[0.5000, 0.5000, 0.5000],\n",
            "         [0.2689, 0.5000, 0.5000]],\n",
            "\n",
            "        [[0.5000, 0.5000, 0.5000],\n",
            "         [0.7311, 0.5000, 0.5000]]])\n",
            "softmax output with pytorch for 3D tensor in dim 1: tensor([[[0.7311, 0.5000, 0.5000],\n",
            "         [0.2689, 0.5000, 0.5000]],\n",
            "\n",
            "        [[0.5000, 0.5000, 0.5000],\n",
            "         [0.5000, 0.5000, 0.5000]]])\n",
            "softmax output with pytorch for 3D tensor in dim 2: tensor([[[0.6590, 0.2424, 0.0986],\n",
            "         [0.4155, 0.4155, 0.1689]],\n",
            "\n",
            "        [[0.6590, 0.2424, 0.0986],\n",
            "         [0.6590, 0.2424, 0.0986]]])\n",
            "cross entropy loss with numpy: 1.4170300162778335\n",
            "cross entropy loss with pytorch: 1.4170299768447876\n",
            "softmax output with pytorch functional: tensor([[0.5017, 0.3043, 0.1940]])\n",
            "Knowledge distillation: -0.08949257433414459 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(2,5)\n",
        "tensor2 = torch.rand(2,5)\n",
        "print(f\"tensor1 : {tensor1}\")\n",
        "print(f\"tensor1 : {tensor2}\")\n",
        "print(f\"addition: {tensor1 + tensor2}\")\n",
        "tensor = torch.rand(2, 3, 4,5)\n",
        "print(tensor)\n",
        "tensor3 = torch.tensor([[[2.0, 1.0, 0.1], [2.0, 1.0, 0.1]] ,[[2.0, 1.0, 0.1], [2.0, 1.0, 0.1]]])\n",
        "print(tensor3.shape)"
      ],
      "metadata": {
        "id": "Qoa99NVH3zHr",
        "outputId": "64cab59a-9319-41f7-bad8-68203295cd02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor1 : tensor([[0.4121, 0.0814, 0.6294, 0.6830, 0.7091],\n",
            "        [0.2044, 0.4821, 0.0080, 0.2398, 0.6811]])\n",
            "tensor1 : tensor([[0.2781, 0.0638, 0.1684, 0.3694, 0.7510],\n",
            "        [0.1884, 0.6669, 0.6748, 0.9250, 0.4021]])\n",
            "addition: tensor([[0.6903, 0.1452, 0.7978, 1.0523, 1.4601],\n",
            "        [0.3928, 1.1490, 0.6827, 1.1647, 1.0832]])\n",
            "tensor([[[[0.9701, 0.6414, 0.0139, 0.3798, 0.2563],\n",
            "          [0.0616, 0.7785, 0.3423, 0.2857, 0.6295],\n",
            "          [0.9482, 0.2272, 0.9472, 0.0610, 0.4925],\n",
            "          [0.9717, 0.2479, 0.0136, 0.9388, 0.4949]],\n",
            "\n",
            "         [[0.0206, 0.6370, 0.0084, 0.0033, 0.1794],\n",
            "          [0.0740, 0.2726, 0.1993, 0.0696, 0.7359],\n",
            "          [0.5071, 0.7440, 0.4200, 0.1331, 0.7226],\n",
            "          [0.8211, 0.2407, 0.9742, 0.3744, 0.3853]],\n",
            "\n",
            "         [[0.1420, 0.6136, 0.3525, 0.2356, 0.8280],\n",
            "          [0.4736, 0.7279, 0.9201, 0.7615, 0.9052],\n",
            "          [0.2509, 0.4007, 0.6267, 0.0033, 0.7524],\n",
            "          [0.8290, 0.1768, 0.5954, 0.9816, 0.9369]]],\n",
            "\n",
            "\n",
            "        [[[0.9215, 0.9197, 0.5631, 0.1644, 0.5980],\n",
            "          [0.5973, 0.7686, 0.3314, 0.7998, 0.0618],\n",
            "          [0.9076, 0.7331, 0.1591, 0.9809, 0.2897],\n",
            "          [0.0366, 0.9977, 0.9910, 0.4638, 0.9866]],\n",
            "\n",
            "         [[0.0763, 0.3312, 0.8218, 0.1697, 0.0407],\n",
            "          [0.0449, 0.6974, 0.0402, 0.5154, 0.4864],\n",
            "          [0.0507, 0.4356, 0.8915, 0.1801, 0.5931],\n",
            "          [0.1591, 0.0464, 0.3819, 0.8676, 0.3853]],\n",
            "\n",
            "         [[0.6330, 0.7310, 0.9218, 0.9693, 0.3189],\n",
            "          [0.6676, 0.0135, 0.6566, 0.0074, 0.8550],\n",
            "          [0.5332, 0.7643, 0.5606, 0.5395, 0.4094],\n",
            "          [0.1241, 0.4853, 0.8184, 0.8793, 0.4991]]]])\n",
            "torch.Size([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "print(x.shape)\n",
        "x = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "print(x.shape)\n",
        "x = torch.tensor([2])\n",
        "print(x.shape)\n",
        "x = torch.tensor([[2.0, 1.0, 0.1], [2.0, 1.0, 0.1]])\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "x0A3--CfH_9k",
        "outputId": "20bd7386-6343-49ed-ee3a-a10a4eece8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([1, 3])\n",
            "torch.Size([1])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class learningWithoutForgetting(object):\n",
        "    def __init__(self, pretrained_model_path, optimizer = 'Adam', num_epochs = 10):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # load model\n",
        "        print(\"Loading the pre-trained model...\")\n",
        "        self.model = models.cnnModel()\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.load_state_dict(copy.deepcopy(torch.load(pretrained_model_path, map_location='cpu')), strict=False)\n",
        "        # Loss function and optimizer\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        \"\"\" Evaluate the model's performance on the test set X_test and y_test\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        X_test: torch tensor of MFCC\n",
        "        y_test: torch tensor of labels\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        accuracy: average accuracy of the model\n",
        "        accuracies: array of accuracy for each class\n",
        "        \"\"\"\n",
        "        accuracy = 0  # average accuracy of the model\n",
        "        accuracies = np.zeros(10)  # accuracy for each class\n",
        "        nb_occurences = np.zeros(10)  # to convert counts to accuracy\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(X_test)):\n",
        "                prediction = self.model.predict(X_test[i].unsqueeze(0).to(device=self.device, dtype=torch.float))\n",
        "                label = (int)(y_test[i].to(device= self.device).item())\n",
        "                if prediction == label:\n",
        "                    accuracies[label] = accuracies[label] + 1\n",
        "                    accuracy = accuracy + 1 \n",
        "                nb_occurences[label] = nb_occurences[label] + 1\n",
        "\n",
        "        accuracy = accuracy / len(X_test)\n",
        "        accuracies = np.divide(accuracies, nb_occurences)\n",
        "\n",
        "        return accuracy, accuracies\n",
        "\n",
        "    def addNovelClassesToModel(self, noNovelClasses):\n",
        "      #add new novel classes to pre-trained model\n",
        "      #add new class parameters , here we have added 3 new classes\n",
        "      input_features = self.model.fc3.in_features\n",
        "      output_features = self.model.fc3.out_features\n",
        "      print(f\"Old model: {model}\")\n",
        "\n",
        "      new_output_features = output_features + noNovelClasses\n",
        "      print(f\"new output features: {new_output_features}\")\n",
        "\n",
        "      self.model.fc3 = nn.Linear(in_features=input_features, out_features= new_output_features)\n",
        "\n",
        "      input_features = model.fc3.in_features\n",
        "      output_features = model.fc3.out_features\n",
        "      print(f\"New model input features: {input_features}\")\n",
        "      print(f\"New model output features: {output_features}\")\n",
        "\n",
        "      # params = list(model.parameters())\n",
        "      # print(f\"Number of total parameters used in a network: {len(params)}\")\n",
        "      print(f\"New model; {model}\")\n",
        "\n",
        "      #initialize new weights with something ***\n",
        "\n",
        "\n",
        "      pass \n",
        "\n",
        "      \n",
        "    def train(self, train_loader):\n",
        "        best_accuracy = 0.0\n",
        "        print(\"Started adaptation of a model !\")\n",
        "        prev_model = copy.deepcopy(self.model)\n",
        "        #todo : add novel classes to pre-trained model\n",
        "        self.addNovelClassesToModel(noNovelClasses = len(random_targets))\n",
        "        for epoch in range(self.num_epochs):\n",
        "          for i, (inputs, labels) in enumerate(train_loader):          \n",
        "            # input = input.unsqueeze(1).float().to(self.device)\n",
        "            # label = label.unsqueeze(0).long().to(self.device)\n",
        "            self.model.train()\n",
        "            running_loss = 0.0\n",
        "            self.optimizer.zero_grad()\n",
        "            logits = self.model(inputs) #batch_size x 14\n",
        "            loss_new = F.cross_entropy(logits, labels)\n",
        "            #calculate old loss\n",
        "            #todo: check no of in_features in liner layer, because we are passing new data here \n",
        "            old_logits = prev_model(inputs)\n",
        "            loss_old = knowledge_distillation_loss(old_logits=old_logits, \n",
        "                                                   updated_logits=logits[:, :-3]) # updates logits of size batch_size x 11 (only old logits)\n",
        "            total_loss = 1*loss_old + loss_new ##todo: what ablout regularization term?\n",
        "            total_loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def test(self, inputs, labels):\n",
        "        self.accuracy, self.accuracies = self.evaluate_model(inputs, labels)\n",
        "        return"
      ],
      "metadata": {
        "id": "idjrdz7-No7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = \"./savedmodels/best_model_state.pt\"\n",
        "batch = torch.load(new_training_samples_path)\n",
        "inputs = torch.cat(batch, dim=0)\n",
        "digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "labels = torch.tensor(digits)\n",
        "\n",
        "# test for different outputs:\n",
        "meta_dataloader = MetaAudioDataLoader(10, 0.2)\n",
        "test_inputs, test_labels = meta_dataloader.get_test_samples(5)\n",
        "# Analysis for Adam tranfer learning\n",
        "tl_adam = learningWithoutForgetting(pretrained_model_path=FILE_PATH, num_epochs=2)\n",
        "tl_adam.cl_train(inputs, labels)\n",
        "tl_adam.test(test_inputs, test_labels)\n",
        "\n",
        "print(tl_adam.accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL1zqFWKOAbn",
        "outputId": "efdd89aa-6a4d-48b9-8db4-d9cb8651b6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/git_projects/AudioClassificationWithDeepLearningAnalysis/dataset/Meta_Dataloader.py:57: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  inputs = torch.tensor(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the pre-trained model...\n",
            "Started adaptation of a model !\n",
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y2Wk_KsLgDg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}