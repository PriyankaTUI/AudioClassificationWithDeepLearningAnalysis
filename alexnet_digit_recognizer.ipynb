{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaTUI/AudioClassificationWithDeepLearningAnalysis/blob/master/alexnet_digit_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PriyankaTUI/AudioClassificationWithDeepLearningAnalysis.git\n",
        "%cd AudioClassificationWithDeepLearningAnalysis\n",
        "!pwd"
      ],
      "metadata": {
        "id": "f59FfBa_PnMh",
        "outputId": "51837b8a-0365-4ef6-aa1b-1dacc2b2b4a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AudioClassificationWithDeepLearningAnalysis'...\n",
            "remote: Enumerating objects: 236, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 236 (delta 61), reused 46 (delta 28), pack-reused 145\u001b[K\n",
            "Receiving objects: 100% (236/236), 44.53 MiB | 26.11 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "/content/AudioClassificationWithDeepLearningAnalysis\n",
            "/content/AudioClassificationWithDeepLearningAnalysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33jWHzjePl6K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import models\n",
        "from torch.utils.data import DataLoader,random_split,Dataset\n",
        "# from torchsummary import summary\n",
        "# from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "#load tensorboard to monitor training\n",
        "%load_ext tensorboard\n",
        "import torch.utils.tensorboard as tb\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# import time\n",
        "from utils import label_to_index, index_to_label, get_average_of_list\n",
        "from dataset import SubsetSC\n",
        "# import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "# from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoETyLrpPl6S"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey9Cw-22Pl6T"
      },
      "source": [
        "**Pre-dataprocessing and data loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp_lFMblPl6W"
      },
      "outputs": [],
      "source": [
        "digits = ['zero','one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'] \n",
        "train_dataset = SubsetSC(\"training\", \"old\")\n",
        "test_dataset = SubsetSC(\"testing\", \"old\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5bupHBVPl6Y"
      },
      "outputs": [],
      "source": [
        "train_labels = [os.path.basename(os.path.dirname(w)) for w in train_dataset._walker]\n",
        "test_labels = [os.path.basename(os.path.dirname(w)) for w in test_dataset._walker]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtQn_0rpPl6Z"
      },
      "source": [
        "**Visualize data to avoid Data Imbalancing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd4Pz1QMPl6a"
      },
      "outputs": [],
      "source": [
        "plt.hist(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WZrgBY8Pl6b"
      },
      "outputs": [],
      "source": [
        "plt.hist(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21V_qa3_Pl6c"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pad_sequence(batch):\n",
        "    # Make all tensor in a batch the same length by padding with zeros\n",
        "    batch = [item.t() for item in batch]\n",
        "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
        "    return batch.permute(0, 2, 1)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "        tensors, targets = [], []\n",
        "        for waveform, label in batch:\n",
        "                tensors += [torch.squeeze(waveform)]\n",
        "                targets += [label_to_index(digits, label)]\n",
        "                \n",
        "        tensors = torch.unsqueeze(pad_sequence(tensors), 1)\n",
        "        targets = torch.stack(targets)\n",
        "        return tensors, targets\n",
        "\n",
        "\n",
        "# old_traindata, old_testdata = torch.utils.data.random_split(old_data_set, [round(len(old_data_set)*.8), round(len(old_data_set)*.2)])\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=64, collate_fn=collate_fn, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=64, collate_fn=collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVmPufLzPl6d"
      },
      "source": [
        "**Training for spoken digit recognizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDuXRZeTPl6d"
      },
      "outputs": [],
      "source": [
        "print(\"Initializing the neural network...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "model = models.AlexNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "writer = SummaryWriter()\n",
        "# Training loop\n",
        "num_epoch = 10\n",
        "best_accuracy = 0.0\n",
        "print(\"Started training !\")\n",
        "for epoch in tqdm(range(num_epoch), total=num_epoch, leave=False):\n",
        "  running_loss = []\n",
        "  validation_loss = []\n",
        "  accuracy = []\n",
        "\n",
        "  for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader), leave=False, desc=f'Epoch: {epoch}/{num_epoch}'): \n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(inputs) #batch_size x 14\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "    running_loss.append(loss.item())\n",
        "\n",
        "  print(f'Epoch {epoch}/{num_epoch}... Loss: {sum(running_loss)/len(running_loss)}')\n",
        "  writer.add_scalars('Loss', {'Train':sum(running_loss)/len(running_loss)}, epoch)\n",
        "\n",
        "  # Evaluate the model on the test set every 10 epochs\n",
        "  if epoch % 5 == 0:\n",
        "    #validation loss and accuracy for novel classes\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      for i, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader), leave=False, desc=f'Epoch: {epoch}/{num_epoch}'):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        logits = model(inputs)\n",
        "        loss = F.cross_entropy(logits,labels)\n",
        "        validation_loss.append(loss.item())\n",
        "        _, pred = logits.max(1)\n",
        "        acc = (pred == labels).sum().item() / pred.size(0) #pred size= [batch_size, no of classes] e.g(10,14)\n",
        "        accuracy.append(acc)\n",
        "      \n",
        "      batch_validation_loss = sum(validation_loss)/len(validation_loss)\n",
        "      print(f'Epoch {epoch}/{num_epoch}... Validation loss: {batch_validation_loss}')\n",
        "      writer.add_scalars('Loss', {'Test':batch_validation_loss}, epoch)\n",
        "      # Saving model if accuracy on the test set is better than previous best model\n",
        "      batch_accuracy = sum(accuracy)/len(accuracy)\n",
        "      print(f'Epoch {epoch}/{num_epoch}... Accuracy: {batch_accuracy}')\n",
        "      writer.add_scalars('Accuracy', {'Test': batch_accuracy}, epoch)\n",
        "      \n",
        "      if batch_accuracy > best_accuracy:\n",
        "          best_accuracy = batch_accuracy\n",
        "          torch.save(model.state_dict(), 'checkpoint_alexnet.pth')\n",
        "          torch.save(optimizer.state_dict(), 'optimizer_checkpoint_alexnet.pth')\n",
        "          print(f'Best model saved at epoch {epoch}/{num_epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UItLquA8Pl6e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('HiWi')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "51dab522930012ad002a27911cbffd3066aed72b8db7b08beb90266f5e36f855"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}