{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaTUI/AudioClassificationWithDeepLearningAnalysis/blob/master/joint_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5byyaMDcpaSt",
        "outputId": "98a7967f-71c6-4a82-af9e-468fa2a7da05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AudioClassificationWithDeepLearningAnalysis\n",
            "/content/AudioClassificationWithDeepLearningAnalysis\n"
          ]
        }
      ],
      "source": [
        "!!git clone https://github.com/PriyankaTUI/AudioClassificationWithDeepLearningAnalysis.git\n",
        "%cd AudioClassificationWithDeepLearningAnalysis\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9gYvRXHbpaS7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import models\n",
        "import copy\n",
        "import os.path\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from utils import label_to_index, index_to_label, get_average_of_list, calculate_accuracy\n",
        "from dataset import SubsetSC\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from statistics import mean \n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZTXLhpu3paS8"
      },
      "outputs": [],
      "source": [
        "#list of novel class targets that we'd use for further training \n",
        "random_targets = ['follow']\n",
        "# random_targets = ['follow','marvin', 'sheila', 'backward']\n",
        "\n",
        "#here we need training data in the combination of digits(i.e old) and new class\n",
        "traindata = SubsetSC(\"training\", \"novel\", novel_class_list= random_targets, dataset_length=80)\n",
        "testdata = SubsetSC(\"testing\", \"novel\", novel_class_list= random_targets, dataset_length=20)\n",
        "# traindata = SubsetSC(\"training\", \"novel\", novel_class_list= random_targets)\n",
        "# testdata = SubsetSC(\"testing\", \"novel\", novel_class_list= random_targets)\n",
        "\n",
        "#for classification labels would be combination of novel classes and old classes(digits)\n",
        "digits = ['zero','one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'] \n",
        "total_targets_list =  digits +random_targets\n",
        "\n",
        "def pad_sequence(batch):\n",
        "    # Make all tensor in a batch the same length by padding with zeros\n",
        "    batch = [item.t() for item in batch]\n",
        "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
        "    return batch.permute(0, 2, 1)\n",
        "\n",
        "def collate_fn(batch):\n",
        "        tensors, targets = [], []\n",
        "        for waveform, label in batch:\n",
        "                tensors += [torch.squeeze(waveform)]\n",
        "                targets += [label_to_index(total_targets_list, label)]\n",
        "                \n",
        "        tensors = torch.unsqueeze(pad_sequence(tensors), 1)\n",
        "        targets = torch.stack(targets)\n",
        "        return tensors, targets\n",
        "        \n",
        "novel_train_dataloader = DataLoader(traindata,batch_size=20, collate_fn=collate_fn, shuffle=True)\n",
        "novel_test_dataloader = DataLoader(testdata, batch_size = 20, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "# old_testdata = SubsetSC(\"testing\", \"old\", dataset_length=100)\n",
        "old_testdata = SubsetSC(\"testing\", \"old\")\n",
        "old_test_dataloader = DataLoader(old_testdata,batch_size=20, collate_fn=collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hg-2u41TpaS-"
      },
      "outputs": [],
      "source": [
        "def get_convnet(convnet_type):\n",
        "    name = convnet_type.lower()\n",
        "    if name == \"vgg\":\n",
        "      FILE_PATH = \"./savedmodels/vgg_checkpoint.pth\"\n",
        "      print(\"getting VGG pre-trained model\")\n",
        "      vgg_model = models.VGGNet()\n",
        "      vgg_model.load_state_dict(copy.deepcopy(torch.load(FILE_PATH, map_location='cpu')), strict=False)\n",
        "      return vgg_model\n",
        "    elif name == \"alexnet\":\n",
        "      FILE_PATH = \"./savedmodels/checkpoint_alexnet.pth\"\n",
        "      print(\"getting AlexNet pre-trained model\")\n",
        "      alexnet_model = models.AlexNet()\n",
        "      alexnet_model.load_state_dict(copy.deepcopy(torch.load(FILE_PATH, map_location='cpu')), strict=False)\n",
        "      return alexnet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yF1GC2I6paS-"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ws9AVcsGpaTA"
      },
      "outputs": [],
      "source": [
        "init_labels = {\n",
        " 'negative' : 'Negative',\n",
        " 'negative_norm' : 'Negative_with_Normalization',\n",
        " 'random' : 'Random',\n",
        " 'random_norm' : 'Random_with_Normalization',\n",
        " 'xavier_uniform' : 'Xavier_Uniform',\n",
        " 'xavier_uniform_norm' : 'Xavier_Uniform_with_Normalization',\n",
        " 'xavier_normal' : 'Xavier_Normal',\n",
        " 'xavier_normal_norm' : 'Xavier_Normal_with_Normalization',\n",
        " 'kaiming_uniform' : 'Kaiming_Uniform',\n",
        " 'kaiming_uniform_norm' : 'Kaiming_Uniform_with_Normalization',\n",
        " 'kaiming_normal' : 'Kaiming_Normal',\n",
        " 'kaiming_normal_norm' : 'Kaiming_Normal_with_Normalization'\n",
        "}\n",
        "\n",
        "def _normalization(old_weights,  incremental_model_linear_weights):\n",
        "  # L2 regularization of weights\n",
        "  old_weights_norm = torch.norm(old_weights, p=2, dim=1)\n",
        "  incremental_model_linear_weights_norm = torch.norm(incremental_model_linear_weights, p=2, dim=1)\n",
        "  old_weights_mean = torch.mean(old_weights_norm)\n",
        "  incremental_model_linear_weights_mean = torch.mean(incremental_model_linear_weights_norm)\n",
        "  gamma = old_weights_mean+incremental_model_linear_weights_mean\n",
        "  old_weights = old_weights/gamma\n",
        "  incremental_model_linear_weights = incremental_model_linear_weights/gamma\n",
        "\n",
        "  return old_weights, incremental_model_linear_weights\n",
        "  \n",
        "def _incremental_model(model, init_method = init_labels['random'], is_normalize = False, _no_out_features:int = 11, _no_novel_class: int = 1):\n",
        "  in_features = model.linear.in_features\n",
        "  out_features = model.linear.out_features\n",
        "  incremental_model_linear = nn.Linear(in_features=in_features, out_features=_no_novel_class)\n",
        "  # incremental_model_linear.to(device)\n",
        "  # model.to(device)\n",
        "  \n",
        "  #Initialize weights \n",
        "  if init_method == init_labels['negative']:\n",
        "    print(f'Initialization: {init_method}')\n",
        "    nn.init.constant_(incremental_model_linear.weight, -1)\n",
        "  elif init_method == init_labels['xavier_uniform']:\n",
        "    print(f'Initialization: {init_method}')\n",
        "    nn.init.xavier_uniform_(incremental_model_linear.weight)\n",
        "  elif init_method == init_labels['xavier_normal']:\n",
        "    print(f'Initialization: {init_method}')\n",
        "    nn.init.xavier_normal_(incremental_model_linear.weight)\n",
        "  elif init_method == init_labels['kaiming_uniform']:\n",
        "    print(f'Initialization: {init_method}')\n",
        "    nn.init.kaiming_uniform_(incremental_model_linear.weight, nonlinearity='linear')\n",
        "  elif init_method == init_labels['kaiming_normal']:\n",
        "    print(f'Initialization: {init_method}')\n",
        "    nn.init.kaiming_normal_(incremental_model_linear.weight)\n",
        "\n",
        "  nn.init.constant_(incremental_model_linear.bias, 0)\n",
        "\n",
        "  old_weights = copy.deepcopy(model.linear.weight.data)\n",
        "  old_bias = copy.deepcopy(model.linear.bias.data)\n",
        "  incremental_model_linear_weights = copy.deepcopy(incremental_model_linear.weight.data)\n",
        "  incremental_model_linear_bias = copy.deepcopy(incremental_model_linear.bias.data)\n",
        "  # model.linear = nn.Linear(in_features=in_features, out_features=len(total_targets_list))\n",
        "  model.linear = nn.Linear(in_features=in_features, out_features=_no_out_features)\n",
        "\n",
        "  if is_normalize:\n",
        "    #if L2 normalization is used\n",
        "    print('with L2 normalization')\n",
        "    old_weights, incremental_model_linear_weights = _normalization(old_weights,  incremental_model_linear_weights\n",
        "                                                                   )\n",
        "  new_weights = torch.cat([old_weights, incremental_model_linear_weights], dim=0)\n",
        "  new_bias = torch.cat([old_bias, incremental_model_linear_bias] ,dim=0)\n",
        "  model.linear.weight.data = new_weights\n",
        "  model.linear.bias.data = new_bias\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aPReXTiLpaTC"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, test_dataloader, old_test_dataloader, optimizer,scheduler, model, num_epochs, log = []):\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = []\n",
        "    running_accuracy = []\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      logits = model(inputs) #batch_size x len(old + novel)\n",
        "      loss = F.cross_entropy(logits, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() \n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      running_loss.append(loss.item())\n",
        "      _, pred = logits.max(1)\n",
        "      acc = (pred == labels).sum().item() / pred.size(0)\n",
        "      running_accuracy.append(acc)\n",
        "    train_loss = mean(running_loss)\n",
        "    train_accuracy = mean(running_accuracy)\n",
        "    test_accuracy , test_loss = calculate_accuracy(dataloader=test_dataloader, model=model)\n",
        "    old_class_accuracy, old_class_loss = calculate_accuracy(dataloader=old_test_dataloader, model=model)\n",
        "    print(f\"Epoch [{epoch}]... train_loss: {train_loss}, train_acc: {train_accuracy}\")\n",
        "    print(f\"\\t     val_loss: {test_loss}, val_acc: {test_accuracy}\")\n",
        "    print(f\"\\t     old_loss: {old_class_loss}, old_acc: {old_class_accuracy}\")\n",
        "    log.append({\n",
        "    'epoch': epoch,\n",
        "    'train_loss': train_loss,\n",
        "    'train_accuracy': train_accuracy,\n",
        "    'val_loss': test_loss,\n",
        "    'val_accuracy': test_accuracy,\n",
        "    'old_class_loss' : old_class_loss,\n",
        "    'old_class_accuracy': old_class_accuracy\n",
        "    })\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T9stPIEspaTD"
      },
      "outputs": [],
      "source": [
        "#combine old and novel classes for joint training\n",
        "# old_traindata = SubsetSC(\"training\", \"old\")\n",
        "old_traindata = SubsetSC(\"training\", \"old\", dataset_length=100)\n",
        "traindata._walker += old_traindata._walker\n",
        "joint_train_dataloader = DataLoader(traindata,batch_size=20, collate_fn=collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1MoMlITpaTD"
      },
      "outputs": [],
      "source": [
        "#optimizer for new training\n",
        "# learning_rate = 0.005\n",
        "# weight_decay = 1e-3\n",
        "# # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,40,80,120,150], gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CkEzE7TVpaTE",
        "outputId": "c02dc979-b729-47b8-9f24-9ecf729f0bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the pre-trained model...\n",
            "getting VGG pre-trained model\n",
            "Initialization: Xavier_Uniform\n",
            "with L2 normalization\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "# T = 2\n",
        "# alpha = 1\n",
        "weight_decay = 1e-6\n",
        "num_epochs = 50\n",
        "log = []\n",
        "_network = 'vgg'\n",
        "\n",
        "# #Model \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load model\n",
        "print(\"Loading the pre-trained model...\")\n",
        "model = get_convnet(\"vgg\")\n",
        "\n",
        "#save old accuracy before increment\n",
        "old_class_accuracy, old_class_loss = calculate_accuracy(dataloader=old_test_dataloader, model=model)\n",
        "log.append({\n",
        "  'epoch': -1,\n",
        "  'train_loss': np.nan,\n",
        "  'train_accuracy': 0,\n",
        "  'val_loss': np.nan,\n",
        "  'val_accuracy': 0,\n",
        "  'old_class_loss' : old_class_loss,\n",
        "  'old_class_accuracy': old_class_accuracy\n",
        "  })\n",
        "#save prev model before increment\n",
        "prev_model = copy.deepcopy(model)\n",
        "#freeze previous model\n",
        "for param in prev_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Add weights at the last linear layer for novel class \n",
        "# model = _incremental_model(model, init_labels['random'], is_normalize = True)\n",
        "# model = _incremental_model(model, init_labels['negative'], is_normalize = True)\n",
        "model = _incremental_model(model, init_labels['xavier_uniform'], is_normalize = True)\n",
        "# model = _incremental_model(model, init_labels['kaiming_uniform'], is_normalize = True)\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,50,70,80], gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mqzNU9G3paTF",
        "outputId": "6c48235e-12ae-4ece-d8f7-9397fd7a1892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0]... train_loss: 4.366666603088379, train_acc: 0.555\n",
            "\t     val_loss: 1.7621726989746094, val_acc: 0.4\n",
            "\t     old_loss: 1.044160008430481, old_acc: 0.8277739251040221\n",
            "Epoch [1]... train_loss: 3.4625913977622984, train_acc: 0.485\n",
            "\t     val_loss: 1.7303606271743774, val_acc: 0.4\n",
            "\t     old_loss: 0.639082133769989, old_acc: 0.8279472954230236\n",
            "Epoch [2]... train_loss: 3.235955238342285, train_acc: 0.515\n",
            "\t     val_loss: 1.7191359996795654, val_acc: 0.4\n",
            "\t     old_loss: 0.7024175524711609, old_acc: 0.8321081830790569\n",
            "Epoch [3]... train_loss: 2.706482934951782, train_acc: 0.51\n",
            "\t     val_loss: 1.7187694311141968, val_acc: 0.4\n",
            "\t     old_loss: 0.08441773802042007, old_acc: 0.833252427184466\n",
            "Epoch [4]... train_loss: 3.364532446861267, train_acc: 0.515\n",
            "\t     val_loss: 1.718988060951233, val_acc: 0.4\n",
            "\t     old_loss: 0.8244221806526184, old_acc: 0.8332871012482663\n",
            "Epoch [5]... train_loss: 3.266454076766968, train_acc: 0.46\n",
            "\t     val_loss: 1.7187738418579102, val_acc: 0.4\n",
            "\t     old_loss: 0.2449350506067276, old_acc: 0.8337378640776699\n",
            "Epoch [6]... train_loss: 3.0775581121444704, train_acc: 0.52\n",
            "\t     val_loss: 1.7184302806854248, val_acc: 0.4\n",
            "\t     old_loss: 0.16142858564853668, old_acc: 0.8332871012482663\n",
            "Epoch [7]... train_loss: 3.185977077484131, train_acc: 0.475\n",
            "\t     val_loss: 1.7183984518051147, val_acc: 0.4\n",
            "\t     old_loss: 0.5703026056289673, old_acc: 0.8332871012482663\n",
            "Epoch [8]... train_loss: 2.9893231272697447, train_acc: 0.52\n",
            "\t     val_loss: 1.7183939218521118, val_acc: 0.4\n",
            "\t     old_loss: 0.42526623606681824, old_acc: 0.8337378640776699\n",
            "Epoch [9]... train_loss: 2.980833202600479, train_acc: 0.48000000000000004\n",
            "\t     val_loss: 1.7183889150619507, val_acc: 0.4\n",
            "\t     old_loss: 1.1433440446853638, old_acc: 0.8328363384188627\n",
            "Epoch [10]... train_loss: 3.0349855780601502, train_acc: 0.48\n",
            "\t     val_loss: 1.7183853387832642, val_acc: 0.4\n",
            "\t     old_loss: 0.06435097754001617, old_acc: 0.8337378640776699\n",
            "Epoch [11]... train_loss: 3.446251058578491, train_acc: 0.49\n",
            "\t     val_loss: 1.7183812856674194, val_acc: 0.4\n",
            "\t     old_loss: 1.0054494142532349, old_acc: 0.8323855755894591\n",
            "Epoch [12]... train_loss: 2.763545572757721, train_acc: 0.535\n",
            "\t     val_loss: 1.7183761596679688, val_acc: 0.4\n",
            "\t     old_loss: 0.9368821978569031, old_acc: 0.8319348127600554\n",
            "Epoch [13]... train_loss: 3.1284432649612426, train_acc: 0.475\n",
            "\t     val_loss: 1.718374490737915, val_acc: 0.4\n",
            "\t     old_loss: 0.35330817103385925, old_acc: 0.8332871012482663\n",
            "Epoch [14]... train_loss: 2.989667510986328, train_acc: 0.51\n",
            "\t     val_loss: 1.7183732986450195, val_acc: 0.4\n",
            "\t     old_loss: 0.48405271768569946, old_acc: 0.8332871012482663\n",
            "Epoch [15]... train_loss: 3.3293965578079225, train_acc: 0.49\n",
            "\t     val_loss: 1.7183732986450195, val_acc: 0.4\n",
            "\t     old_loss: 0.7010217308998108, old_acc: 0.8328363384188627\n",
            "Epoch [16]... train_loss: 3.076843333244324, train_acc: 0.545\n",
            "\t     val_loss: 1.7183717489242554, val_acc: 0.4\n",
            "\t     old_loss: 0.22040127217769623, old_acc: 0.8332871012482663\n",
            "Epoch [17]... train_loss: 3.9765683889389036, train_acc: 0.485\n",
            "\t     val_loss: 1.7183719873428345, val_acc: 0.4\n",
            "\t     old_loss: 0.5412502288818359, old_acc: 0.8332871012482663\n",
            "Epoch [18]... train_loss: 3.5592811465263368, train_acc: 0.505\n",
            "\t     val_loss: 1.7183730602264404, val_acc: 0.4\n",
            "\t     old_loss: 0.6519173383712769, old_acc: 0.8328363384188627\n",
            "Epoch [19]... train_loss: 3.53042471408844, train_acc: 0.45\n",
            "\t     val_loss: 1.7183723449707031, val_acc: 0.4\n",
            "\t     old_loss: 0.4262172281742096, old_acc: 0.8337378640776699\n",
            "Epoch [20]... train_loss: 2.955909764766693, train_acc: 0.48\n",
            "\t     val_loss: 1.7183706760406494, val_acc: 0.4\n",
            "\t     old_loss: 0.9722536206245422, old_acc: 0.8332871012482663\n",
            "Epoch [21]... train_loss: 3.0602741599082948, train_acc: 0.53\n",
            "\t     val_loss: 1.7183668613433838, val_acc: 0.4\n",
            "\t     old_loss: 0.3434089124202728, old_acc: 0.8337378640776699\n",
            "Epoch [22]... train_loss: 2.5582711577415465, train_acc: 0.49\n",
            "\t     val_loss: 1.718362808227539, val_acc: 0.4\n",
            "\t     old_loss: 0.10898014158010483, old_acc: 0.8337378640776699\n",
            "Epoch [23]... train_loss: 3.91496022939682, train_acc: 0.455\n",
            "\t     val_loss: 1.7183620929718018, val_acc: 0.4\n",
            "\t     old_loss: 0.82480388879776, old_acc: 0.8328363384188627\n",
            "Epoch [24]... train_loss: 3.1827638864517214, train_acc: 0.47000000000000003\n",
            "\t     val_loss: 1.7183603048324585, val_acc: 0.4\n",
            "\t     old_loss: 0.3866823613643646, old_acc: 0.8332871012482663\n",
            "Epoch [25]... train_loss: 3.5248926520347594, train_acc: 0.495\n",
            "\t     val_loss: 1.7183606624603271, val_acc: 0.4\n",
            "\t     old_loss: 0.31765228509902954, old_acc: 0.8337378640776699\n",
            "Epoch [26]... train_loss: 3.183010387420654, train_acc: 0.45\n",
            "\t     val_loss: 1.7183634042739868, val_acc: 0.4\n",
            "\t     old_loss: 0.32815319299697876, old_acc: 0.8332871012482663\n",
            "Epoch [27]... train_loss: 2.266714334487915, train_acc: 0.515\n",
            "\t     val_loss: 1.718362808227539, val_acc: 0.4\n",
            "\t     old_loss: 0.6902371644973755, old_acc: 0.8332871012482663\n",
            "Epoch [28]... train_loss: 2.624160182476044, train_acc: 0.525\n",
            "\t     val_loss: 1.7183606624603271, val_acc: 0.4\n",
            "\t     old_loss: 0.5720661878585815, old_acc: 0.8332871012482663\n",
            "Epoch [29]... train_loss: 3.301722502708435, train_acc: 0.46499999999999997\n",
            "\t     val_loss: 1.7183587551116943, val_acc: 0.4\n",
            "\t     old_loss: 0.09235125035047531, old_acc: 0.8337378640776699\n",
            "Epoch [30]... train_loss: 2.7101144671440123, train_acc: 0.5\n",
            "\t     val_loss: 1.7183583974838257, val_acc: 0.4\n",
            "\t     old_loss: 0.44051074981689453, old_acc: 0.8328363384188627\n",
            "Epoch [31]... train_loss: 3.651560640335083, train_acc: 0.47\n",
            "\t     val_loss: 1.718356728553772, val_acc: 0.4\n",
            "\t     old_loss: 0.026987319812178612, old_acc: 0.8337378640776699\n",
            "Epoch [32]... train_loss: 3.4793325543403624, train_acc: 0.46\n",
            "\t     val_loss: 1.7183568477630615, val_acc: 0.4\n",
            "\t     old_loss: 0.5696063041687012, old_acc: 0.8332871012482663\n",
            "Epoch [33]... train_loss: 3.629441523551941, train_acc: 0.48\n",
            "\t     val_loss: 1.7183573246002197, val_acc: 0.4\n",
            "\t     old_loss: 0.31932690739631653, old_acc: 0.8332871012482663\n",
            "Epoch [34]... train_loss: 3.326422244310379, train_acc: 0.49\n",
            "\t     val_loss: 1.7183539867401123, val_acc: 0.4\n",
            "\t     old_loss: 1.1207367181777954, old_acc: 0.8323855755894591\n",
            "Epoch [35]... train_loss: 3.4370640873908997, train_acc: 0.47\n",
            "\t     val_loss: 1.718353509902954, val_acc: 0.4\n",
            "\t     old_loss: 0.819848358631134, old_acc: 0.8323855755894591\n",
            "Epoch [36]... train_loss: 3.393698680400848, train_acc: 0.545\n",
            "\t     val_loss: 1.7183513641357422, val_acc: 0.4\n",
            "\t     old_loss: 0.8737872242927551, old_acc: 0.8328363384188627\n",
            "Epoch [37]... train_loss: 3.836181843280792, train_acc: 0.47\n",
            "\t     val_loss: 1.7183492183685303, val_acc: 0.4\n",
            "\t     old_loss: 1.6470829248428345, old_acc: 0.8328363384188627\n",
            "Epoch [38]... train_loss: 3.0731310725212095, train_acc: 0.45\n",
            "\t     val_loss: 1.7183458805084229, val_acc: 0.4\n",
            "\t     old_loss: 0.06089993193745613, old_acc: 0.8337378640776699\n",
            "Epoch [39]... train_loss: 2.531938624382019, train_acc: 0.46\n",
            "\t     val_loss: 1.7183443307876587, val_acc: 0.4\n",
            "\t     old_loss: 0.5437703132629395, old_acc: 0.8332871012482663\n",
            "Epoch [40]... train_loss: 3.47649804353714, train_acc: 0.525\n",
            "\t     val_loss: 1.7183418273925781, val_acc: 0.4\n",
            "\t     old_loss: 0.4216625988483429, old_acc: 0.8332871012482663\n",
            "Epoch [41]... train_loss: 3.2383367657661437, train_acc: 0.465\n",
            "\t     val_loss: 1.7183395624160767, val_acc: 0.4\n",
            "\t     old_loss: 0.2599561810493469, old_acc: 0.8337378640776699\n",
            "Epoch [42]... train_loss: 3.0338311314582826, train_acc: 0.495\n",
            "\t     val_loss: 1.7183386087417603, val_acc: 0.4\n",
            "\t     old_loss: 0.41721823811531067, old_acc: 0.8328363384188627\n",
            "Epoch [43]... train_loss: 3.1539865732192993, train_acc: 0.525\n",
            "\t     val_loss: 1.7183393239974976, val_acc: 0.4\n",
            "\t     old_loss: 0.9148823618888855, old_acc: 0.8328363384188627\n",
            "Epoch [44]... train_loss: 3.1810097694396973, train_acc: 0.495\n",
            "\t     val_loss: 1.7183387279510498, val_acc: 0.4\n",
            "\t     old_loss: 0.16950011253356934, old_acc: 0.8332871012482663\n",
            "Epoch [45]... train_loss: 3.314117431640625, train_acc: 0.435\n",
            "\t     val_loss: 1.7183376550674438, val_acc: 0.4\n",
            "\t     old_loss: 0.46257951855659485, old_acc: 0.8332871012482663\n",
            "Epoch [46]... train_loss: 2.917089915275574, train_acc: 0.455\n",
            "\t     val_loss: 1.7183377742767334, val_acc: 0.4\n",
            "\t     old_loss: 0.24194589257240295, old_acc: 0.8332871012482663\n",
            "Epoch [47]... train_loss: 3.6495906591415403, train_acc: 0.49\n",
            "\t     val_loss: 1.7183376550674438, val_acc: 0.4\n",
            "\t     old_loss: 0.2965782582759857, old_acc: 0.8337378640776699\n",
            "Epoch [48]... train_loss: 2.9222861886024476, train_acc: 0.505\n",
            "\t     val_loss: 1.7183393239974976, val_acc: 0.4\n",
            "\t     old_loss: 1.079949975013733, old_acc: 0.8328363384188627\n",
            "Epoch [49]... train_loss: 3.5074402570724486, train_acc: 0.5\n",
            "\t     val_loss: 1.718340516090393, val_acc: 0.4\n",
            "\t     old_loss: 1.804273009300232, old_acc: 0.8323855755894591\n"
          ]
        }
      ],
      "source": [
        "train(train_dataloader= joint_train_dataloader, \n",
        "      test_dataloader= novel_test_dataloader, \n",
        "      old_test_dataloader= old_test_dataloader,\n",
        "      optimizer= optimizer, \n",
        "      model= model, \n",
        "      num_epochs= num_epochs, \n",
        "      scheduler= scheduler, \n",
        "      log = log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e0h59yFpaTG"
      },
      "outputs": [],
      "source": [
        "df_log = pd.DataFrame(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaaNOhLbpaTH",
        "outputId": "05fb2882-5d63-41c5-8cbe-58543bbc351c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved training data to file results_joint_training_Random_with_Normalization_2022-11-07_15.39.01.424899\n"
          ]
        }
      ],
      "source": [
        "# df_log = pd.DataFrame(log)\n",
        "filename = str(datetime.now().date()) + '_' + str(datetime.now().time()).replace(':', '.')\n",
        "path = \"results_joint_training_\" + str(init_labels['random_norm']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['random']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['negative']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['negative_norm']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['xavier_uniform']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['xavier_uniform_norm']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['kaiming_uniform']) + '_' + filename\n",
        "# path = \"results_joint_training_\" + str(init_labels['kaiming_uniform_norm']) + '_' + filename\n",
        "\n",
        "df_log.to_pickle(path)\n",
        "print(f\"Saved training data to file {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN3EgDH4paTI",
        "outputId": "10e8739e-2d7b-4f62-e808-a28eaa52b9ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
        "# plt.rc('text', usetex=False)\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "title_str = 'Accuracy comparision for Joint Training with ' + init_labels['random'] +  ' initialization and Normalization'\n",
        "plt.plot(df_log[['train_accuracy']], label = 'Novel train', marker = '.')\n",
        "plt.plot(df_log[['val_accuracy']], label = 'Novel Val', marker = '.')\n",
        "plt.plot(df_log[['old_class_accuracy']], label= 'Old Class', marker = '.')\n",
        "plt.legend()\n",
        "plt.title('Accuracy comparision for Joint Training with ' + init_labels['random'] +  ' initialization and Normalization',fontsize=15, weight = 'bold')\n",
        "# plt.figtext(0, 0.9, 'Accuracy', fontsize=20, weight = 'extra bold',  ha ='left')\n",
        "# plt.figtext(0.14, 0.9, ' comparision for Joint Training w.r.t ' + init_labels['random'] +  ' initialization and Normalization',fontsize=15, weight = 'bold')\n",
        "plt.yticks(np.arange(0,1.1,0.1), weight = 'bold')\n",
        "plt.xticks(weight = 'bold')\n",
        "plt.xlabel('Epoch', weight = 'bold')\n",
        "plt.ylabel('Accuracy', weight = 'bold')\n",
        "\n",
        "fig.savefig(title_str + \".png\", format=\"png\", dpi=600, bbox_inches=\"tight\")\n",
        "fig.savefig(title_str + \".eps\", format=\"eps\", dpi=1200, bbox_inches=\"tight\", transparent=True)\n",
        "fig.savefig(title_str + \".pdf\", format=\"pdf\", dpi=1200, bbox_inches=\"tight\", transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multitask joint training"
      ],
      "metadata": {
        "id": "xouyiFjd4-o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "# T = 2\n",
        "# alpha = 1\n",
        "weight_decay = 1e-6\n",
        "num_epochs = 10\n",
        "log = []\n",
        "_network = 'vgg'\n",
        "\n",
        "# #Model \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load model\n",
        "print(\"Loading the pre-trained model...\")\n",
        "model = get_convnet(\"vgg\")\n",
        "\n",
        "#save old accuracy before increment\n",
        "old_class_accuracy, old_class_loss = calculate_accuracy(dataloader=old_test_dataloader, model=model)\n",
        "log.append({\n",
        "  'epoch': -1,\n",
        "  'train_loss': np.nan,\n",
        "  'train_accuracy': 0,\n",
        "  'val_loss': np.nan,\n",
        "  'val_accuracy': 0,\n",
        "  'old_class_loss' : old_class_loss,\n",
        "  'old_class_accuracy': old_class_accuracy\n",
        "  })"
      ],
      "metadata": {
        "id": "vIM7yxQZ5cyb",
        "outputId": "4b2835bf-67c0-4d64-ea0c-b546039fedbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the pre-trained model...\n",
            "getting VGG pre-trained model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "M8ZW06o5paTO",
        "outputId": "f6632745-80bb-41d4-deaf-06d680b35303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization: Xavier_Uniform\n",
            "with L2 normalization\n",
            "Training for follow\n",
            "Epoch [0]... train_loss: 7.690428972244263, train_acc: 0.29333333333333333\n",
            "\t     val_loss: 1.472421407699585, val_acc: 0.55\n",
            "\t     old_loss: 1.0386003255844116, old_acc: 0.7838418862690707\n",
            "Epoch [1]... train_loss: 2.921527640024821, train_acc: 0.42666666666666664\n",
            "\t     val_loss: 1.5098457336425781, val_acc: 0.6\n",
            "\t     old_loss: 1.981845736503601, old_acc: 0.7957004160887656\n",
            "Epoch [2]... train_loss: 3.389219705263774, train_acc: 0.38\n",
            "\t     val_loss: 1.391479253768921, val_acc: 0.35\n",
            "\t     old_loss: 0.2321021854877472, old_acc: 0.8393203883495146\n",
            "Epoch [3]... train_loss: 2.8328088760375976, train_acc: 0.42\n",
            "\t     val_loss: 2.0455973148345947, val_acc: 0.30000000000000004\n",
            "\t     old_loss: 0.40404587984085083, old_acc: 0.8405339805825243\n",
            "Epoch [4]... train_loss: 2.2250957171122234, train_acc: 0.42\n",
            "\t     val_loss: 1.2642781734466553, val_acc: 0.4\n",
            "\t     old_loss: 0.18015113472938538, old_acc: 0.8495145631067961\n",
            "Epoch [5]... train_loss: 2.6039242506027223, train_acc: 0.41333333333333333\n",
            "\t     val_loss: 1.5750445127487183, val_acc: 0.55\n",
            "\t     old_loss: 0.6381486654281616, old_acc: 0.8456657420249654\n",
            "Epoch [6]... train_loss: 2.5135721524556476, train_acc: 0.4066666666666667\n",
            "\t     val_loss: 1.4792063236236572, val_acc: 0.5\n",
            "\t     old_loss: 0.7314831614494324, old_acc: 0.8563453536754507\n",
            "Epoch [7]... train_loss: 2.1416961471239726, train_acc: 0.5\n",
            "\t     val_loss: 0.3595902621746063, val_acc: 1.0\n",
            "\t     old_loss: 2.35343599319458, old_acc: 0.7952149791955617\n",
            "Epoch [8]... train_loss: 2.3667622963587442, train_acc: 0.49333333333333335\n",
            "\t     val_loss: 1.1971595287322998, val_acc: 0.6\n",
            "\t     old_loss: 1.3572852611541748, old_acc: 0.8488210818307905\n",
            "Epoch [9]... train_loss: 2.0418171246846515, train_acc: 0.44\n",
            "\t     val_loss: 1.17192542552948, val_acc: 0.65\n",
            "\t     old_loss: 0.6518023610115051, old_acc: 0.8490638002773925\n",
            "Training for marvin\n",
            "Epoch [0]... train_loss: 3.009951043128967, train_acc: 0.3066666666666667\n",
            "\t     val_loss: 3.385568141937256, val_acc: 0.0\n",
            "\t     old_loss: 0.743057370185852, old_acc: 0.8624479889042996\n",
            "Epoch [1]... train_loss: 2.6904674688975017, train_acc: 0.3333333333333333\n",
            "\t     val_loss: 2.8131535053253174, val_acc: 0.0\n",
            "\t     old_loss: 0.3813078999519348, old_acc: 0.8607142857142858\n",
            "Epoch [2]... train_loss: 2.326579229036967, train_acc: 0.44\n",
            "\t     val_loss: 2.766721725463867, val_acc: 0.4\n",
            "\t     old_loss: 1.646332859992981, old_acc: 0.8275658807212205\n",
            "Epoch [3]... train_loss: 2.388315749168396, train_acc: 0.4066666666666667\n",
            "\t     val_loss: 2.5035107135772705, val_acc: 0.44999999999999996\n",
            "\t     old_loss: 0.49117687344551086, old_acc: 0.8347434119278779\n",
            "Epoch [4]... train_loss: 2.280451289812724, train_acc: 0.49333333333333335\n",
            "\t     val_loss: 1.9974788427352905, val_acc: 0.45\n",
            "\t     old_loss: 0.8414674401283264, old_acc: 0.8378987517337032\n",
            "Epoch [5]... train_loss: 2.348340622584025, train_acc: 0.42\n",
            "\t     val_loss: 2.636462688446045, val_acc: 0.45\n",
            "\t     old_loss: 0.7854706645011902, old_acc: 0.8403259361997226\n",
            "Epoch [6]... train_loss: 2.812367002169291, train_acc: 0.44\n",
            "\t     val_loss: 2.1459434032440186, val_acc: 0.55\n",
            "\t     old_loss: 0.4058992266654968, old_acc: 0.8395631067961165\n",
            "Epoch [7]... train_loss: 2.292800724506378, train_acc: 0.5133333333333333\n",
            "\t     val_loss: 2.303128719329834, val_acc: 0.6499999999999999\n",
            "\t     old_loss: 1.662703514099121, old_acc: 0.8364771151178918\n",
            "Epoch [8]... train_loss: 2.01682562828064, train_acc: 0.5066666666666667\n",
            "\t     val_loss: 2.372546911239624, val_acc: 0.75\n",
            "\t     old_loss: 0.541949450969696, old_acc: 0.834257975034674\n",
            "Epoch [9]... train_loss: 1.9589686393737793, train_acc: 0.4866666666666667\n",
            "\t     val_loss: 1.968981385231018, val_acc: 0.75\n",
            "\t     old_loss: 1.018930196762085, old_acc: 0.8338418862690707\n",
            "Training for visual\n",
            "Epoch [0]... train_loss: 4.404954592386882, train_acc: 0.2733333333333333\n",
            "\t     val_loss: 4.810841083526611, val_acc: 0.0\n",
            "\t     old_loss: 0.2733701765537262, old_acc: 0.8454230235783634\n",
            "Epoch [1]... train_loss: 3.53612425327301, train_acc: 0.24666666666666667\n",
            "\t     val_loss: 4.045230388641357, val_acc: 0.0\n",
            "\t     old_loss: 0.3890661597251892, old_acc: 0.851005547850208\n",
            "Epoch [2]... train_loss: 3.0877140204111737, train_acc: 0.31333333333333335\n",
            "\t     val_loss: 3.9699654579162598, val_acc: 0.0\n",
            "\t     old_loss: 0.5467830896377563, old_acc: 0.8568654646324549\n",
            "Epoch [3]... train_loss: 3.5418272733688356, train_acc: 0.26\n",
            "\t     val_loss: 3.4773330688476562, val_acc: 0.0\n",
            "\t     old_loss: 1.0669039487838745, old_acc: 0.8583564493758669\n",
            "Epoch [4]... train_loss: 3.202803301811218, train_acc: 0.24666666666666667\n",
            "\t     val_loss: 2.9409897327423096, val_acc: 0.0\n",
            "\t     old_loss: 0.0916367918252945, old_acc: 0.8628640776699029\n",
            "Epoch [5]... train_loss: 2.711508313814799, train_acc: 0.3933333333333333\n",
            "\t     val_loss: 1.984940767288208, val_acc: 0.44999999999999996\n",
            "\t     old_loss: 0.9907777905464172, old_acc: 0.8413314840499306\n",
            "Epoch [6]... train_loss: 2.1579986492792766, train_acc: 0.48\n",
            "\t     val_loss: 0.9037531018257141, val_acc: 0.7\n",
            "\t     old_loss: 0.27984729409217834, old_acc: 0.7777045769764216\n",
            "Epoch [7]... train_loss: 1.8569850007692972, train_acc: 0.5066666666666667\n",
            "\t     val_loss: 1.0452253818511963, val_acc: 0.7\n",
            "\t     old_loss: 0.6704263091087341, old_acc: 0.8000693481276006\n",
            "Epoch [8]... train_loss: 2.2440096616744993, train_acc: 0.44666666666666666\n",
            "\t     val_loss: 1.4344940185546875, val_acc: 0.6499999999999999\n",
            "\t     old_loss: 0.5051192045211792, old_acc: 0.8172676837725381\n",
            "Epoch [9]... train_loss: 2.3469333171844484, train_acc: 0.43333333333333335\n",
            "\t     val_loss: 1.2341927289962769, val_acc: 0.7\n",
            "\t     old_loss: 0.24334372580051422, old_acc: 0.8075242718446602\n",
            "Training for house\n",
            "Epoch [0]... train_loss: 3.8352533181508384, train_acc: 0.23333333333333334\n",
            "\t     val_loss: 3.5841941833496094, val_acc: 0.0\n",
            "\t     old_loss: 1.0238018035888672, old_acc: 0.8428224687933425\n",
            "Epoch [1]... train_loss: 3.109919706980387, train_acc: 0.28\n",
            "\t     val_loss: 2.989959955215454, val_acc: 0.0\n",
            "\t     old_loss: 0.6432842016220093, old_acc: 0.8643550624133148\n",
            "Epoch [2]... train_loss: 2.5929073969523113, train_acc: 0.31333333333333335\n",
            "\t     val_loss: 2.8018765449523926, val_acc: 0.0\n",
            "\t     old_loss: 0.7601171731948853, old_acc: 0.8658460471567268\n",
            "Epoch [3]... train_loss: 2.839964811007182, train_acc: 0.2733333333333333\n",
            "\t     val_loss: 2.752178430557251, val_acc: 0.0\n",
            "\t     old_loss: 0.46145692467689514, old_acc: 0.8660540915395284\n",
            "Epoch [4]... train_loss: 2.814869483311971, train_acc: 0.28\n",
            "\t     val_loss: 2.5710816383361816, val_acc: 0.0\n",
            "\t     old_loss: 0.40526899695396423, old_acc: 0.8669902912621359\n",
            "Epoch [5]... train_loss: 2.1965529680252076, train_acc: 0.4266666666666667\n",
            "\t     val_loss: 1.3582360744476318, val_acc: 1.0\n",
            "\t     old_loss: 0.8083874583244324, old_acc: 0.8039528432732316\n",
            "Epoch [6]... train_loss: 2.057655700047811, train_acc: 0.49333333333333335\n",
            "\t     val_loss: 1.140344262123108, val_acc: 1.0\n",
            "\t     old_loss: 0.41907432675361633, old_acc: 0.7983356449375867\n",
            "Epoch [7]... train_loss: 2.247499187787374, train_acc: 0.48\n",
            "\t     val_loss: 1.4370520114898682, val_acc: 1.0\n",
            "\t     old_loss: 0.7501763105392456, old_acc: 0.8175450762829404\n",
            "Epoch [8]... train_loss: 1.730943771203359, train_acc: 0.5599999999999999\n",
            "\t     val_loss: 1.1242115497589111, val_acc: 1.0\n",
            "\t     old_loss: 0.3652203679084778, old_acc: 0.8067961165048544\n",
            "Epoch [9]... train_loss: 2.064028290907542, train_acc: 0.5066666666666667\n",
            "\t     val_loss: 1.0646260976791382, val_acc: 1.0\n",
            "\t     old_loss: 0.21043650805950165, old_acc: 0.8029126213592233\n",
            "Training for happy\n",
            "Epoch [0]... train_loss: 4.667318058013916, train_acc: 0.2866666666666667\n",
            "\t     val_loss: 5.85879373550415, val_acc: 0.0\n",
            "\t     old_loss: 0.5150426030158997, old_acc: 0.8651178918169209\n",
            "Epoch [1]... train_loss: 3.446839992205302, train_acc: 0.30666666666666664\n",
            "\t     val_loss: 3.635892868041992, val_acc: 0.0\n",
            "\t     old_loss: 0.08067764341831207, old_acc: 0.8635922330097088\n",
            "Epoch [2]... train_loss: 2.7745138963063556, train_acc: 0.37333333333333335\n",
            "\t     val_loss: 2.6458630561828613, val_acc: 0.75\n",
            "\t     old_loss: 0.6045501828193665, old_acc: 0.8226074895977808\n",
            "Epoch [3]... train_loss: 2.2727014382680255, train_acc: 0.4666666666666667\n",
            "\t     val_loss: 1.7001869678497314, val_acc: 0.8\n",
            "\t     old_loss: 1.0537810325622559, old_acc: 0.8144244105409154\n",
            "Epoch [4]... train_loss: 2.118429978688558, train_acc: 0.5066666666666666\n",
            "\t     val_loss: 2.029086112976074, val_acc: 0.8500000000000001\n",
            "\t     old_loss: 0.5997980237007141, old_acc: 0.8221567267683773\n",
            "Epoch [5]... train_loss: 2.146677819887797, train_acc: 0.47333333333333333\n",
            "\t     val_loss: 1.6084296703338623, val_acc: 0.8500000000000001\n",
            "\t     old_loss: 0.11279280483722687, old_acc: 0.8189320388349515\n",
            "Epoch [6]... train_loss: 2.130126404762268, train_acc: 0.44666666666666666\n",
            "\t     val_loss: 1.212100625038147, val_acc: 0.9\n",
            "\t     old_loss: 0.24866726994514465, old_acc: 0.8135922330097087\n",
            "Epoch [7]... train_loss: 1.9777617772420248, train_acc: 0.5266666666666666\n",
            "\t     val_loss: 1.3265495300292969, val_acc: 0.9\n",
            "\t     old_loss: 0.6069297790527344, old_acc: 0.8058599167822469\n",
            "Epoch [8]... train_loss: 2.0529893080393475, train_acc: 0.4866666666666667\n",
            "\t     val_loss: 1.2009931802749634, val_acc: 0.9\n",
            "\t     old_loss: 0.013041958212852478, old_acc: 0.8138349514563107\n",
            "Epoch [9]... train_loss: 1.6945947249730429, train_acc: 0.56\n",
            "\t     val_loss: 1.6096856594085693, val_acc: 0.85\n",
            "\t     old_loss: 0.7748140096664429, old_acc: 0.8219140083217753\n"
          ]
        }
      ],
      "source": [
        "multiclass_learning = [\"follow\", \"marvin\", \"visual\", \"house\", \"happy\"]\n",
        "digits = ['zero','one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'] \n",
        "new_targets_list = digits\n",
        "\n",
        "_temp = digits + multiclass_learning\n",
        "old_traindata = SubsetSC(\"training\", \"old\", dataset_length=100)\n",
        "\n",
        "#save prev model before increment\n",
        "prev_model = copy.deepcopy(model)\n",
        "#freeze previous model\n",
        "for param in prev_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "#increse last nodes in multiclass\n",
        "# model = _incremental_model(model, is_normalize = True, _no_out_features = 15, _no_novel_class=len(multiclass_learning))\n",
        "model = _incremental_model(model, init_method=init_labels['xavier_uniform'], is_normalize = True, _no_out_features = 15, _no_novel_class=len(multiclass_learning))\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200], gamma=0.1) #dont want scheduler here\n",
        "\n",
        "old_traindata = SubsetSC(\"training\", \"old\", dataset_length=100)\n",
        "#for loop to learn novel tasks one by one and record old tasks performance during training.\n",
        "for _class_name in multiclass_learning:\n",
        "  print(f\"Training for {_class_name}\")\n",
        "  traindata = SubsetSC(\"training\", \"novel\", novel_class_list= [_class_name], dataset_length=50)\n",
        "  testdata = SubsetSC(\"testing\", \"novel\", novel_class_list= [_class_name], dataset_length=20)\n",
        "  new_targets_list += [_class_name]\n",
        "  def collate_fn(batch):\n",
        "          tensors, targets = [], []\n",
        "          for waveform, label in batch:\n",
        "                  tensors += [torch.squeeze(waveform)]\n",
        "                  targets += [label_to_index(_temp, label)]\n",
        "          tensors = torch.unsqueeze(pad_sequence(tensors), 1)\n",
        "          targets = torch.stack(targets)\n",
        "          return tensors, targets\n",
        "  traindata._walker += old_traindata._walker\n",
        "  new_novel_train_dataloader = DataLoader(traindata,batch_size=10, collate_fn=collate_fn, shuffle=True)\n",
        "  new_novel_test_dataloader = DataLoader(testdata, batch_size = 10, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "  train(train_dataloader= new_novel_train_dataloader, \n",
        "      test_dataloader= new_novel_test_dataloader, \n",
        "      old_test_dataloader= old_test_dataloader,\n",
        "      optimizer= optimizer, \n",
        "      model= model, \n",
        "      num_epochs= num_epochs, \n",
        "      scheduler= scheduler, \n",
        "      log = log)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5cSdxXA75yl5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('HiWi')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "51dab522930012ad002a27911cbffd3066aed72b8db7b08beb90266f5e36f855"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}